---
output: html_document
editor_options: 
  chunk_output_type: console
chunk_output_type: console
---

```{r}
source('setup.R')
df = read.csv('data/dat_count.csv', sep = ';')
```

# Clothing insulation level: Count data

## Generalized linear model based on Binomial distribution
A generalized linear model based on the Binomial distribution predicting the number of times a individual subject changes clothing insulation level throughout the day ($clo$). This will be based on the total time ($time$) of each observation, the number of observations during each day ($nobs$), the sex of the subject ($sex$), and the average indoor ($tInOp$) and outdoor temperature ($tOut$). As it is based on a binomial distribution this results in $Y = Z/n$ where $Z \sim B(n, p)$ where $n$ is $nobs$ and $p$ is the probability that a individual subject changes clothing insulation level per day. The response modeled using the binomial distribution is the number of times that a subject changes clothing insulation level per day and the number times they don't (successes and fails). The model consist of a linear predictor $\eta_i$ which is the mapping of the $\mu_i$ using the link function $g$. Creating the following relation $\eta_i = g(\mu_i)$ and $\mu_i = g^{-1}(\eta_i)$. 

The generalized linear model based on the Binomial distribution will be fitted using the logit link-function. The full model using all interactions will be reduced based on Type II partitioning (based on the Chi-squared distribution) using backward selection. Higher order terms will be removed before lower order terms. Also a goodness of fit test will be applied in order to test if the model is sufficient.

As the first full model containing all interactions does not pass the goodness of fit test ($p = 0.0086$). This indicates that the residual deviance is larger than what can be explained by the chi-squared distribution (ref Madsen). This could also indicate wrong distributional assumptions. Other link functions are also tried out in order to test if these could pass the goodness of fit test including: probit ($p = 0.00882$), cauchit ($p = 0.0095$), log ($p= 0.0082$) and cloglog ($p= 0.0084$). None of these passes the goodness of fit test. Basis expansion of time, outdoor and indoor temperature are tried up to order three and combined with all the before mentioned link functions but none of these passes the goodness of fit test. This could indicate that either the input variables does not appear to be good predictors of the output variable or that the binomial distribution is not a proper choice.


```{r}
############Question 1 with binomial: 

df$resp = cbind(df$clo, df$nobs - df$clo)
fit0  = glm(resp ~ time*sex*tOut*tInOp,binomial, data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#DOES NOT FOLLOW RESIDUAL ASSUMPTIONS
#Remove time:sex:tOut:tInOp

#Possible selections: logit(default), probit, cauchit, log, cloglog
fit14probit = glm(resp~  time*sex*tOut*tInOp, family = binomial(link = 'probit'), data = df)
drop1(fit14probit, test = 'Chisq')
1 - pchisq(fit14probit$deviance,df=fit14probit$df.residual)
#Fails goodness of fit test 

fit14cauchit = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'cauchit'), data = df)
drop1(fit14cauchit, test = 'Chisq')
1 - pchisq(fit14cauchit$deviance,df=fit14cauchit$df.residual)
#Fails goodness of fit test 

fit14log = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'log'), data = df)
drop1(fit14log, test = 'Chisq')
1 - pchisq(fit14log$deviance,df=fit14log$df.residual)
#Fails goodness of fit test 

fit14cloglog = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'cloglog'), data = df)
drop1(fit14cloglog, test = 'Chisq')
1 - pchisq(fit14cloglog$deviance,df=fit14cloglog$df.residual)
#Fails goodness of fit test 

fit1 = glm(resp~  time*sex*tOut*tInOp + poly(time,degree= 2)+poly(time,degree= 3)+
             poly(tInOp,degree= 2)+poly(tInOp,degree= 3)+poly(tOut,degree= 2)+
             poly(tOut,degree= 3), family = binomial(link = 'probit'), data = df)
1 - pchisq(fit1$deviance,df=fit1$df.residual)
fit1 = glm(resp~  time*sex*tOut*tInOp + poly(time,degree= 2)+poly(time,degree= 3)+
             poly(tInOp,degree= 2)+poly(tInOp,degree= 3)+poly(tOut,degree= 2)+
             poly(tOut,degree= 3), family = binomial(link = 'log'), data = df)
1 - pchisq(fit1$deviance,df=fit1$df.residual)
fit1 = glm(resp~  time*sex*tOut*tInOp + poly(time,degree= 2)+poly(time,degree= 3)+
             poly(tInOp,degree= 2)+poly(tInOp,degree= 3)+poly(tOut,degree= 2)+
             poly(tOut,degree= 3), family = binomial(link = 'cloglog'), data = df)
1 - pchisq(fit1$deviance,df=fit1$df.residual)
fit1 = glm(resp~  time*sex*tOut*tInOp + poly(time,degree= 2)+poly(time,degree= 3)+
             poly(tInOp,degree= 2)+poly(tInOp,degree= 3)+poly(tOut,degree= 2)+
             poly(tOut,degree= 3), family = binomial(link = 'cauchit'), data = df)
1 - pchisq(fit1$deviance,df=fit1$df.residual)

```



As different link-functions and basis expansion of the input variables does not pass the goodness of fit test a generalized linear model based on the binomial distribution containing an overdispersion parameter will be proposed. The initial model will be a full model containing all interactions and this will be reduced using backward selection based on Type II partitioning (based on F-distribution), where higher order terms are removed first. The resulting model is presented below using the logit link functions:
```{r}
#All link functions with the final and full models fails. 
##Need to do overdispersion or create more complex model
fit1quasi = glm(resp~  time*sex*tOut*tInOp, family = quasibinomial, data = df)
drop1(fit1quasi, test = 'F')

fit2quasi  = update(fit1quasi, .~ . - time:sex:tOut:tInOp, data = df)
drop1(fit2quasi, test = 'F')

fit3quasi  = update(fit2quasi, .~ . -time:tOut:tInOp , data = df)
drop1(fit3quasi, test = 'F')
fit4quasi  = update(fit3quasi, .~ . -time:sex:tOut , data = df)
drop1(fit4quasi, test = 'F')
fit5quasi  = update(fit4quasi, .~ . -time:sex:tInOp  , data = df)
drop1(fit5quasi, test = 'F')
fit6quasi  = update(fit5quasi, .~ . -sex:tOut:tInOp  , data = df)
drop1(fit6quasi, test = 'F')
fit7quasi  = update(fit6quasi, .~ . -tOut:tInOp    , data = df)
drop1(fit7quasi, test = 'F')
fit8quasi  = update(fit7quasi, .~ . -sex:tOut     , data = df)
drop1(fit8quasi, test = 'F')
fit9quasi  = update(fit8quasi, .~ . -time:tOut      , data = df)
drop1(fit9quasi, test = 'F')
fit10quasi  = update(fit9quasi, .~ . -time:tInOp      , data = df)
drop1(fit10quasi, test = 'F')
fit11quasi  = update(fit10quasi, .~ . -time:sex      , data = df)
drop1(fit11quasi, test = 'F')
fit12quasi  = update(fit11quasi, .~ . -sex:tInOp        , data = df)
drop1(fit12quasi, test = 'F')
fit13quasi  = update(fit12quasi, .~ . -tOut            , data = df)
drop1(fit13quasi, test = 'F')
fit14quasi  = update(fit13quasi, .~ . -tInOp            , data = df)
drop1(fit14quasi, test = 'F')
fit15quasi  = update(fit14quasi, .~ . -time            , data = df)
drop1(fit15quasi, test = 'F')

anova(fit1quasi, fit15quasi, test ='Chisq')

fit16quasi <- update(fit15quasi, .~. + I((tInOp-mean(tInOp))^2) + I((tOut-mean(tOut))^2) + I((time-mean(time))^2), data = df)
drop1(fit16quasi, test = 'F')

fit16quasi <- update(fit16quasi, .~.  -I((tOut-mean(tOut))^2), data = df)
drop1(fit16quasi, test = 'F')
fit17quasi <- update(fit16quasi, .~.  -I((tInOp-mean(tInOp))^2), data = df)
drop1(fit17quasi, test = 'F')
```


$$p_{clo,i} = g^{-1}(\beta_0 + \beta_1 \cdot sex_i + \epsilon_i)$$

where $\epsilon_i \sim B_i(0,\sigma^2)$. Here $p_{clo,i}$ is the probability of changing clothing level. The residuals are assumed to be independent and identically distributed. The standard deviation of the residuals ($\hat{\sigma}$) are estimated as 1.13 and a confidence hereof are calculated based on theorem 3.5. The estimated parameters and 95\% confidence intervals calculated based on profile likelihood can be seen in table \ref{table:par_binomial}. 
To test the model reduction a likelihood-ratio-test are performed based on theorem 3.6 resulting in $p=0.84$ thereby the model reduction is kept. Basis expansions of time, indoor and outdoor temperature are tried out but these are removed as they appear not to be significant. 

```{r}
library(xtable)
fit15quasi$coefficients
xtable(confint(fit15quasi))


lm_sigma_conf<-function(fit,CI=0.95){
  # Book page 53: sigma_hat^2~sigma^2*chisq_f/f where f=n-k
  # rearanging: sigma_hat^2*f/chisq_f
  sigma=sigma(fit)
  d_f=fit$df.residual
  conf_sigma2=d_f*sigma^2/qchisq(c((1-CI)/2,1-(1-CI)/2), df = d_f, lower.tail = FALSE)
  conf=sqrt(conf_sigma2)
  names(conf)=paste(c((1-CI)/2,1-(1-CI)/2)*100,"%")
  return(conf)
}
sigma(fit15quasi)
lm_sigma_conf(fit15quasi)
```

\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & 2.5 \% & Estimate & 97.5 \% \\ 
  \hline
$\hat{\beta_0}$ & -1.91 & -1.57 &-1.26 \\ 
  $\hat{\beta_1}$ & -1.84 & -1.18 & -0.58 \\ 
  $\hat{\sigma}$ & 1.01 & 1.13 & 1.29 \\
   \hline
\end{tabular}
\label{table:par_binomial}
\caption{Estimated parameter values for the generalized linear model based on binomial distribution and 95 \% confidence interval based on profile likelihood. Also 95\% confidence interval of residual standard deviation. }
\end{table}
```{r}
summary(fit15quasi)
(sigsq.dev <- fit15quasi$deviance/fit15quasi$df.residual)
(sigsq.pear <- sum(residuals(fit15quasi,type="pearson")^2)/fit15quasi$df.residual)
(sigsq.devR <- sum(residuals(fit15quasi,type="deviance")^2)/fit15quasi$df.residual)

```
The overdispersions parameter is estimated as: 1.34 based on pearson residuals. The residuals of the final model are investigated further in figure \ref{fig:residuals_binomial}. From the Residuals vs. Fitted and Scale-Location plots in figure \ref{fig:residuals_binomial} there does not appear to be any apparent issues with the residuals. The input variables are discrete as this is the gender of the subject and therefore this is expected. The Normal-QQ plot does not look correct, but as the $nobs_i$ of the data are low it is not expected that the standardized deviance residuals are approximately Gaussian. 

```{r residuals_binomial,fig.height=8,fig.cap="Residuals analysis of the generalized linear model based on the binomial distribution."}
par(mfrow= c(2,2))
plot(fit15quasi)
```


## Generalized linear model based on Poisson distribution

A new generalized linear model similar the the one proposed above are fitted. Instead of being based on the binomial distribution the new model will be based on the Poisson distribution using the log link-function. The predictor $\eta_i$ is the mapped version of $\mu$ using the link function $g$ giving the following relation: $\eta_i = g(\mu_i)$. The initial model are again the full model using all interactions, and are reduced using the backward selection method using Type II partitioning (based on the Chi-squared distribution), where higher order terms are removed before lower order terms. A goodness of fit test are performed on the initial model resulting in: $p = 0.13$ and therefore passes the initial goodness of fit test. The final from the model reduction is presented below: 

```{r}
fit0  = glm(clo ~ time*factor(sex)*tOut*tInOp ,poisson(link = log), data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#Remove fourth order interaction

fit1  = update(fit0, .~ . -time:factor(sex):tOut:tInOp   , data = df)
drop1(fit1, test = 'Chisq')
1 - pchisq(fit1$deviance,df=fit1$df.residual)
#Remove sex:tOut:tInOp

fit2 = update(fit1, .~ . -factor(sex):tOut:tInOp   , data = df)
drop1(fit2, test = 'Chisq')
1 - pchisq(fit2$deviance,df=fit2$df.residual)
#Remove time:tOut:tInOp

fit3 = update(fit2, .~ . -time:tOut:tInOp   , data = df)
drop1(fit3, test = 'Chisq')
1 - pchisq(fit3$deviance,df=fit3$df.residual)
#Remove time:sex:tOut
fit4 = update(fit3, .~ . -time:factor(sex):tOut   , data = df)
drop1(fit4, test = 'Chisq')
1 - pchisq(fit4$deviance,df=fit4$df.residual)
fit5 = update(fit4, .~ . -time:factor(sex):tInOp   , data = df)
drop1(fit5, test = 'Chisq')
1 - pchisq(fit5$deviance,df=fit5$df.residual)
#Remove tOut:tInOp
fit6 = update(fit5, .~ . -tOut:tInOp   , data = df)
drop1(fit6, test = 'Chisq')
1 - pchisq(fit6$deviance,df=fit6$df.residual)
#Remove sex:tOut
fit7 = update(fit6, .~ . -factor(sex):tOut   , data = df)
drop1(fit7, test = 'Chisq')
1 - pchisq(fit7$deviance,df=fit7$df.residual)
#Remove time:tOut
fit8 = update(fit7, .~ . -time:tOut   , data = df)
drop1(fit8, test = 'Chisq')
1 - pchisq(fit8$deviance,df=fit8$df.residual)
#Remove time:tInOp
fit9 = update(fit8, .~ . -time:tInOp   , data = df)
drop1(fit9, test = 'Chisq')
1 - pchisq(fit9$deviance,df=fit9$df.residual)
#Remove sex:tInOp
fit10 = update(fit9, .~ . -factor(sex):tInOp   , data = df)
drop1(fit10, test = 'Chisq')
1 - pchisq(fit10$deviance,df=fit10$df.residual)
fit11 = update(fit10, .~ . -time:factor(sex)   , data = df)
drop1(fit11, test = 'Chisq')
1 - pchisq(fit11$deviance,df=fit11$df.residual)
#Remove tOut
fit12 = update(fit11, .~ . -tOut   , data = df)
drop1(fit12, test = 'Chisq')
1 - pchisq(fit12$deviance,df=fit12$df.residual)
#Remove tInOp
fit13 = update(fit12, .~ . -tInOp   , data = df)
drop1(fit13, test = 'Chisq')
1 - pchisq(fit13$deviance,df=fit13$df.residual)
#remove time
fit14 = update(fit13, .~ . -time   , data = df)
drop1(fit14, test = 'Chisq')
1 - pchisq(fit14$deviance,df=fit14$df.residual)
anova(fit0, fit14, test = 'Chisq')
```

$$clo_i = g^{-1}(\beta_0 + \beta_1 \cdot sex_i + \epsilon_i)$$


where $\epsilon_i \sim P_i(0,\sigma^2)$. Again the reduced model passes the goodness of fit test ($p=0.16$). Also the reduced model are compared with the full initial model in order to test the model reduction (likelihood-ratio-test) and results in the following p-value: $p=0.59$ and the model reduction are therefore kept. The residuals are assumed to be independent and identically distributed. It is further tested whether including an offset will improve the performance of the model. An offset using $log(nobs)$ and another using $log(time)$ are implemented. This would result in the following model when using the log link-function:$\eta_i = log(\dfrac{\mu_i}{offset_i})$. Both models containing offsets performs slightly better than the model without, and all models passes the goodness of fit test. 

The model including the $log(time)$ offset performs slightly better than the other offset model. This model are also tested whether it is a sufficient model and both the full initial model and the reduced model passes the goodness of fit test (initial model: $p = 0.11$, reduced model: $0.16$). Also the reduced model containing an offset ends up with same model as presented above, but including an offset. In order to compare the model including an offset and the previous model the AIC (but the same result emerges when using log-likelihood). The computed AIC scores are: 270.13 and 271.03 for the model including an offset and the one without respectively. Thereby indicating that the model including the $log(time)$ offset are best. When using the time offset the $nobs$ are only added to the model, as this contains the value 1 and when applying the log link-function this results in zeros. Therefore it is only added to the model.   


```{r}
#####Offset nobs:
fit0offset  = glm(clo ~ time*factor(sex)*tOut*tInOp + offset(log(nobs)) ,poisson(link = log), data = df)
drop1(fit0offset, test = 'Chisq')
1 - pchisq(fit0offset$deviance,df=fit0offset$df.residual)
#Reduce with this setting --> compare 
fit1offset  = update(fit0offset, .~ . -time:factor(sex):tOut:tInOp   , data = df)
drop1(fit1offset, test = 'Chisq')
1 - pchisq(fit1offset$deviance,df=fit1offset$df.residual)

fit2offset  = update(fit1offset, .~ . -time:tOut:tInOp    , data = df)
drop1(fit2offset, test = 'Chisq')
1 - pchisq(fit2offset$deviance,df=fit2offset$df.residual)

fit3offset  = update(fit2offset, .~ . -time:factor(sex):tOut    , data = df)
drop1(fit3offset, test = 'Chisq')
1 - pchisq(fit3offset$deviance,df=fit3offset$df.residual)

fit4offset  = update(fit3offset, .~ . -time:factor(sex):tInOp    , data = df)
drop1(fit4offset, test = 'Chisq')
1 - pchisq(fit4offset$deviance,df=fit4offset$df.residual)

fit5offset  = update(fit4offset, .~ . -factor(sex):tOut:tInOp      , data = df)
drop1(fit5offset, test = 'Chisq')
1 - pchisq(fit5offset$deviance,df=fit5offset$df.residual)

fit6offset  = update(fit5offset, .~ . -tOut:tInOp      , data = df)
drop1(fit6offset, test = 'Chisq')
1 - pchisq(fit6offset$deviance,df=fit6offset$df.residual)

fit7offset  = update(fit6offset, .~ . -factor(sex):tOut       , data = df)
drop1(fit7offset, test = 'Chisq')
1 - pchisq(fit7offset$deviance,df=fit7offset$df.residual)

fit8offset  = update(fit7offset, .~ . -time:tOut       , data = df)
drop1(fit8offset, test = 'Chisq')
1 - pchisq(fit8offset$deviance,df=fit8offset$df.residual)

fit9offset  = update(fit8offset, .~ . -time:tInOp    , data = df)
drop1(fit9offset, test = 'Chisq')
1 - pchisq(fit9offset$deviance,df=fit9offset$df.residual)

fit10offset  = update(fit9offset, .~ . -time:factor(sex)    , data = df)
drop1(fit10offset, test = 'Chisq')
1 - pchisq(fit10offset$deviance,df=fit10offset$df.residual)

fit11offset  = update(fit10offset, .~ . -factor(sex):tInOp    , data = df)
drop1(fit11offset, test = 'Chisq')
1 - pchisq(fit11offset$deviance,df=fit11offset$df.residual)

fit12offset  = update(fit11offset, .~ . -tOut    , data = df)
drop1(fit12offset, test = 'Chisq')
1 - pchisq(fit12offset$deviance,df=fit12offset$df.residual)

fit13offset  = update(fit12offset, .~ . -tInOp    , data = df)
drop1(fit13offset, test = 'Chisq')
1 - pchisq(fit13offset$deviance,df=fit13offset$df.residual)

fit14offset  = update(fit13offset, .~ . -time    , data = df)
drop1(fit14offset, test = 'Chisq')
1 - pchisq(fit14offset$deviance,df=fit14offset$df.residual)


###Offset time:
fit0offsett  = glm(clo ~ nobs+factor(sex)*tOut*tInOp + offset(log(time)) ,poisson(link = log), data = df)
drop1(fit0offsett, test = 'Chisq')
1 - pchisq(fit0offsett$deviance,df=fit0offsett$df.residual)
#Reduce with this setting --> compare 
fit1offsett  = update(fit0offsett, .~ . - factor(sex):tOut:tInOp   , data = df)
drop1(fit1offsett, test = 'Chisq')
1 - pchisq(fit1offsett$deviance,df=fit1offsett$df.residual)

fit2offsett  = update(fit1offsett, .~ . -tOut:tInOp      , data = df)
drop1(fit2offsett, test = 'Chisq')
1 - pchisq(fit2offsett$deviance,df=fit2offsett$df.residual)

fit3offsett  = update(fit2offsett, .~ . -factor(sex):tOut       , data = df)
drop1(fit3offsett, test = 'Chisq')
1 - pchisq(fit3offsett$deviance,df=fit3offsett$df.residual)

fit4offsett  = update(fit3offsett, .~ . -factor(sex):tInOp    , data = df)
drop1(fit4offsett, test = 'Chisq')
1 - pchisq(fit4offsett$deviance,df=fit4offsett$df.residual)

fit4offsett  = update(fit4offsett, .~ . -nobs    , data = df)
drop1(fit4offsett, test = 'Chisq')
1 - pchisq(fit4offsett$deviance,df=fit4offsett$df.residual)

fit5offsett  = update(fit4offsett, .~ . -tOut    , data = df)
drop1(fit5offsett, test = 'Chisq')
1 - pchisq(fit5offsett$deviance,df=fit5offsett$df.residual)

fit6offsett  = update(fit5offsett, .~ . -tInOp    , data = df)
drop1(fit6offsett, test = 'Chisq')
1 - pchisq(fit6offsett$deviance,df=fit6offsett$df.residual)


AIC(fit14offset,fit6offsett, fit14)
logLik(fit14offset)
logLik(fit6offsett)
logLik(fit14)



```

Furthermore, basis expansions of time, indoor and outdoor temperature are tested whether this could improve the model performance. Including the basis expansion results in insignificant terms which are therefore removed. 
```{r}
fit0  = glm(clo ~ (sex)*tOut*tInOp + offset(log(time)) +
                    I((tInOp-mean(tInOp))^2) + I((tOut-mean(tOut))^2),poisson(link = log), data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#Reduce with this setting --> compare 
fit1  = update(fit0, .~ . -I((tOut - mean(tOut))^2)   , data = df)
drop1(fit1, test = 'Chisq')
1 - pchisq(fit1$deviance,df=fit1$df.residual)

fit2  = update(fit1, .~ . -I((tInOp - mean(tInOp))^2)    , data = df)
drop1(fit2, test = 'Chisq')
```

Lastly different link-functions are tested whether they can improve the model performance. 
```{r}
glm(clo ~ factor(sex) + offset(log(time)) ,poisson(link = log), data = df)
#ERROR?
#ALSO ERROR WITH TIME^2
```

The final and optimal model are the following: 

$$clo_i = g^{-1}(\beta_0 + \beta_1 \cdot sex_i + offset(log(time_i))+ \epsilon_i)$$

```{r}
lm_sigma_conf<-function(fit,CI=0.95){
  # Book page 53: sigma_hat^2~sigma^2*chisq_f/f where f=n-k
  # rearanging: sigma_hat^2*f/chisq_f
  sigma=sigma(fit)
  d_f=fit$df.residual
  conf_sigma2=d_f*sigma^2/qchisq(c((1-CI)/2,1-(1-CI)/2), df = d_f, lower.tail = FALSE)
  conf=sqrt(conf_sigma2)
  names(conf)=paste(c((1-CI)/2,1-(1-CI)/2)*100,"%")
  return(conf)
}
sigma(fit14offset)
lm_sigma_conf(fit14offset)
fit14offset$coefficients
xtable(confint(fit14offset))
anova(fit0offset, fit14offset, test = 'Chisq')
```

The standard deviation of the residuals ($\hat{\sigma}$) are estimated as 1.06 and a confidence hereof are calculated based on theorem 3.5. The estimated parameters and 95\% confidence intervals calculated based on profile likelihood can be seen in table \ref{table:par_poisson}. 
To test the model reduction a likelihood-ratio-test are performed based on theorem 3.6 resulting in $p=0.26$ thereby the model reduction is kept.

\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & 2.5 \% & Estimate & 97.5 \% \\ 
  \hline
 $\hat{\beta_0}$ & -2.02 & -1.76 & -1.52 \\ 
  $\hat{\beta_1}$ & -1.60 & -1.06 & -0.56 \\
  $\hat{\sigma}$ & 0.94 & 1.06 & 1.20 \\
   \hline
\end{tabular}
\label{table:par_poisson}
\caption{Estimated parameter values for the generalized linear model based on poisson distribution and 95 \% confidence interval based on profile likelihood. Also 95\% confidence interval of residual standard deviation.}
\end{table}

The residuals are also investigated in figure \ref{fig:residuals_poisson}. From this the Residuals vs Fitted and Scale-Location plots looks fine, as there does not appear to be any structure in the residuals.  The Normal-QQ plot does not look correct, but as the count of the data ($clo_i$) are low it is not expected that the standardized deviance residuals are approximately Gaussian. 
```{r residuals_poisson,fig.height=8,fig.cap="Residuals analysis of the generalized linear model based on the poisson distribution."}
par(mfrow = c(2,2))
plot(fit6offsett)
```


## Interpretation of the two models
The initial generalized linear model based on the binomial distribution did not pass the goodness of fit test, and it was needed to include a overdispersion parameter estimate to 1.34. This could be due to the binomial distribution not being an appropriate distributional assumptions using the provided predictors. As the model contains an intercept $\hat{\beta_0}$ and a slope for the sex of the subject $\hat{\beta_1}$, then the intercept will contain the information about how females changes clothing level throughout the day (as $sex(female) = 0$ and $sex(male) = 1$ ). Whereas $\hat{\beta_1}$ contains the adjustment in the intercept for males as $sex(males)= 1$. The probability of females and males changing clothing insulation level can therefore be calculated as using the following formula: $p = \dfrac{exp(\theta)}{1+exp(\theta)}$. 

$$p_{female} = \dfrac{exp(-1.57)}{1+exp(-1.57)}  = 0.17$$
$$p_{male} = \dfrac{exp(-1.57-1.18)}{1+exp(-1.571.18)}  = 0.06$$
The probability of females changing insulation clothing level are thereby approximately three times as large as for males. This would also correspond to the higher variation in female clothing level compared to males, which was observed in assignment 1. In order to estimate this more correctly the Odds ratio are calculated: 
$$OR = \dfrac{p_{females}/(1-p_{females})}{p_{males}/(1-p_{males})} = \dfrac{0.17/(1-0.17)}{0.06/(1-0.06)}= 3.27$$ 
A 95\% confidence interval of the Odds ratio are: [1.79, 6.32]. As the Odds ratio (and confidence interval) are well above 1 this indicates that females are much more prone to change clothing insulation level than males. 
```{r}
1/exp(coef(fit15quasi)[2])
1/exp(confint(fit15quasi)[2, ]) ## 95% confidence interval
```

For the generalized linear model based on the Poisson distribution the model as well contained an intercept. The model ended up with the same predictors as the generalized linear model based on the binomial distribution. The Poisson model did pass the goodness of fit test thereby indicating that this distributional assumption was more appropriate. Again as described above the intercept would contain information about how the females changes clothing level, whereas the $\hat{beta_1}$ parameter would contain the adjustment for males. The model also included the offset using $log(time)$. From table \ref{table:par_poisson} it can be seen that females again are more prone to changing clothing level than males, as we can see the negative adjustment for males compared to females. As $\hat{\beta_1}$ are negative in the link-space this would result in a smaller mean $\mu_i$ for males and thereby result in a lower probability for changing clothes of males than females. 

Again the Odds ratio are calculated between females and males resulting in OR = $2.90$ and 95\% confidence interval (based on the profile-likelihood) [1.76, 4.98]. This again indicates that females are more likelihood to change clothing level than males. 

```{r}
1/exp(coef(fit6offsett)[2])
1/exp(confint(fit6offsett)[2, ]) ## 95% confidence interval

```


## Small conclusion
A generalized linear model based on the binomial distribution was fitted on the clothing insulation data aiming to predict the change in the individual subjects clothing level throughout a day. This was based on the indoor and outdoor temperature, the gender of the subject and the total time of each observations. Different link-functions and basis expansions of the input variables were tried out but none of the models resulted in a model that passed the goodness of fit test. It was therefore needed to introduce a overdispersion parameter, resulting in the following mode: 

$$p_{clo,i} = g^{-1}(\beta_0 + \beta_1 \cdot sex_i + \epsilon_i)$$

The model was reduced using the backward selection based on Type II partitioning. The odds ratio was calculated between the female and male probability of changing clothing insulation level and this was estimated to $OR = 3.25$ thereby indicating that females are more prone to changing clothing level than males. 

A generalized linear model based on the Poisson distribution was also estimated based on the same input variables. This model did pass the goodness of fit test, and thereby indicating that the distributional assumptions for the Poisson distribution did match the variables much better than the Binomial distribution. It was therefore not needed to estimate an overdispersion parameter. It was found that introducing an offset using the $log(time)$ did improve the performance of the model. The optimal model was as well estimated using the backward selection based on Type II partitioning and result is presented below: 

$$clo_i = g^{-1}(\beta_0 + \beta_1 \cdot sex_i +offset(log(time_i)) + \epsilon_i)$$

It appears for both models that the most important predictor is the gender of the subject. This also appears to be feasible as there are big difference in the variation in the change of clothing level based on the gender. The resulting model for both distributional assumption could indicate that the most predictive and important input variable for determining the change of clothing level are the gender of the subject. 



