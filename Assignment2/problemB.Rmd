---
output: html_document
editor_options: 
  chunk_output_type: console
chunk_output_type: console
---

```{r}
source('setup.R')
library(ggplot)
library(GGally)
df = read.csv('data/dat_count.csv', sep = ';')
```

# Clothing insulation level: Count data

#Generalized linear model based on Binomial distribution
A generalized linear model based on the Binomial distribution predicting the number of times a individual subject changes clothing insulation level throughout the day ($clo$). This will be based on the total time ($time$) of each observation, the number of observations during each day ($nobs$), the sex of the subject ($sex$), and the average indoor ($tInOp$) and outdoor temperature ($tOut$). 

The generalized linear model based on the Binomial distribution will be fitted using the logit link-function. The full model using all interactions will be reduced based on Type III partitioning using backward selection. Higher order terms will be removed before lower order terms. Also a goodness of fit test will be applied in order to test if the model is sufficient.

As the first full model containing all interactions does not pass the goodness of fit test ($p = 0.0086$). This indicates that the residual deviance is larger than what can be explained by the chi-squared distribution (ref Madsen). This could also indicate wrong distributional assumptions. Other link functions are also tried out in order to test if these could pass the goodness of fit test including: probit ($p = 0.00882$), cauchit ($p = 0.0095$), log ($p= 0.0082$) and cloglog ($p= 0.0084$). None of these passes the goodness of fit test. Basis expansion of time, outdoor and indoor temperature as tried up to order three and combined with all the before mentioned link functions but none of these passes the goodness of fit test. This could indicate that either the input variables does not appear to be good predictors of the output variable or that the binomial distribution is not a proper choice.
```{r}
############Question 1 with binomial: 

df$resp = cbind(df$clo, df$nobs - df$clo)
fit0  = glm(resp ~ time*sex*tOut*tInOp,binomial, data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#DOES NOT FOLLOW RESIDUAL ASSUMPTIONS
#Remove time:sex:tOut:tInOp

fit1  = update(fit0, .~ . - time:sex:tOut:tInOp, data = df)
drop1(fit1, test = 'Chisq')
1 - pchisq(fit1$deviance,df=fit1$df.residual)
#DOES NOT FOLLOW RESIDUAL ASSUMPTIONS
#Remove time:tOut:tInOp

fit2  = update(fit1, .~ . - sex:tOut:tInOp   , data = df)
drop1(fit2, test = 'Chisq')
1 - pchisq(fit2$deviance,df=fit2$df.residual)
#Remove time:tOut:tInOp

fit3  = update(fit2, .~ . - time:tOut:tInOp   , data = df)
drop1(fit3, test = 'Chisq')
1 - pchisq(fit3$deviance,df=fit3$df.residual)
#Remove time:sex:tOut

fit4  = update(fit3, .~ . - time:sex:tOut   , data = df)
drop1(fit4, test = 'Chisq')
1 - pchisq(fit4$deviance,df=fit4$df.residual)
#Remove time:sex:tInOp

fit5  = update(fit4, .~ . - time:sex:tInOp   , data = df)
drop1(fit5, test = 'Chisq')
1 - pchisq(fit5$deviance,df=fit5$df.residual)
#Remove tOut:tInOp

fit6  = update(fit5, .~ . - tOut:tInOp   , data = df)
drop1(fit6, test = 'Chisq')
1 - pchisq(fit6$deviance,df=fit6$df.residual)
#Remove sex:tOut

fit7  = update(fit6, .~ . - sex:tOut   , data = df)
drop1(fit7, test = 'Chisq')
1 - pchisq(fit7$deviance,df=fit7$df.residual)
#Remove time:tOut

fit8  = update(fit7, .~ . - time:tOut   , data = df)
drop1(fit8, test = 'Chisq')
1 - pchisq(fit8$deviance,df=fit8$df.residual)
#Remove time:tInOp - higher order terms first!

fit9  = update(fit8, .~ . - time:tInOp   , data = df)
drop1(fit9, test = 'Chisq')
1 - pchisq(fit9$deviance,df=fit9$df.residual)
#Remove time:sex 

fit10  = update(fit9, .~ . - time:sex   , data = df)
drop1(fit10, test = 'Chisq')
1 - pchisq(fit10$deviance,df=fit10$df.residual)
#Remove tOut 

fit11  = update(fit10, .~ . - tOut   , data = df)
drop1(fit11, test = 'Chisq')
1 - pchisq(fit11$deviance,df=fit11$df.residual)
#Remove time 

fit12  = update(fit11, .~ . - time   , data = df)
drop1(fit12, test = 'Chisq')
1 - pchisq(fit12$deviance,df=fit12$df.residual)
#Remove sex:tInOp

fit13  = update(fit12, .~ . - sex:tInOp   , data = df)
drop1(fit13, test = 'Chisq')
1 - pchisq(fit13$deviance,df=fit13$df.residual)
#Remove tInOp

fit14  = update(fit13, .~ . - tInOp   , data = df)
drop1(fit14, test = 'Chisq')
1 - pchisq(fit14$deviance,df=fit14$df.residual)
anova(fit14, test ='Chisq')

anova(fit0, fit14, test = 'Chisq')
#Cant reject model reduction 
c(AIC(fit0),AIC(fit14))
#Improvement in AIC
str(df)

####################################
#################################### None of above models pass the goodness of fit test therefore try out different link functions!
#Possible selections: logit(default), probit, cauchit, log, cloglog
fit14probit = glm(resp~  time*sex*tOut*tInOp, family = binomial(link = 'probit'), data = df)
drop1(fit14probit, test = 'Chisq')
1 - pchisq(fit14probit$deviance,df=fit14probit$df.residual)
#Fails goodness of fit test 

fit14cauchit = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'cauchit'), data = df)
drop1(fit14cauchit, test = 'Chisq')
1 - pchisq(fit14cauchit$deviance,df=fit14cauchit$df.residual)
#Fails goodness of fit test 

fit14log = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'log'), data = df)
drop1(fit14log, test = 'Chisq')
1 - pchisq(fit14log$deviance,df=fit14log$df.residual)
#Fails goodness of fit test 

fit14cloglog = glm(resp~ time*sex*tOut*tInOp, family = binomial(link = 'cloglog'), data = df)
drop1(fit14cloglog, test = 'Chisq')
1 - pchisq(fit14cloglog$deviance,df=fit14cloglog$df.residual)
#Fails goodness of fit test 

fit1 = glm(resp~  time*sex*tOut*tInOp + poly(time,degree= 2)+poly(time,degree= 3)+
             poly(tInOp,degree= 2)+poly(tInOp,degree= 3)+poly(tOut,degree= 2)+
             poly(tOut,degree= 3), family = binomial(link = 'probit'), data = df)


fit1 = glm(resp~  time*sex*tOut*tInOp + I((time-mean(time))^2)+I((time-mean(time))^3)+I((tOut-mean(tOut))^2)+ 
             I((tInOp-mean(tInOp))^2), family = binomial, data = df)
fit1 = glm(resp~  time*sex*tOut*tInOp + I((time)^2)+I((tOut)^2)+ 
             I((tInOp)^2), family = binomial(link = 'cauchit'), data = df)
1 - pchisq(fit1$deviance,df=fit1$df.residual)

```


As different link-functions and basis expansion of the input variables does not pass the goodness of fit test a generalized linear model based on the binomial distribution containing a overdispersion parameter will be proposed. The initial model will be a full model containing all interactions and this will be reduced using backward selection based on Type III partitioning, where higher order terms are removed first. The resulting model is presented below:
```{r}
#All link functions with the final and full models fails. 
##Need to do overdispersion or create more complex model
fit1quasi = glm(resp~  time*sex*tOut*tInOp, family = quasibinomial, data = df)
drop1(fit1quasi, test = 'F')

fit2quasi  = update(fit1quasi, .~ . - time:sex:tOut:tInOp, data = df)
drop1(fit2quasi, test = 'F')

fit3quasi  = update(fit2quasi, .~ . -time:tOut:tInOp , data = df)
drop1(fit3quasi, test = 'F')
fit4quasi  = update(fit3quasi, .~ . -time:sex:tOut , data = df)
drop1(fit4quasi, test = 'F')
fit5quasi  = update(fit4quasi, .~ . -time:sex:tInOp  , data = df)
drop1(fit5quasi, test = 'F')
fit6quasi  = update(fit5quasi, .~ . -sex:tOut:tInOp  , data = df)
drop1(fit6quasi, test = 'F')
fit7quasi  = update(fit6quasi, .~ . -tOut:tInOp    , data = df)
drop1(fit7quasi, test = 'F')
fit8quasi  = update(fit7quasi, .~ . -sex:tOut     , data = df)
drop1(fit8quasi, test = 'F')
fit9quasi  = update(fit8quasi, .~ . -time:tOut      , data = df)
drop1(fit9quasi, test = 'F')
fit10quasi  = update(fit9quasi, .~ . -time:tInOp      , data = df)
drop1(fit10quasi, test = 'F')
fit11quasi  = update(fit10quasi, .~ . -time:sex      , data = df)
drop1(fit11quasi, test = 'F')
fit12quasi  = update(fit11quasi, .~ . -sex:tInOp        , data = df)
drop1(fit12quasi, test = 'F')
fit13quasi  = update(fit12quasi, .~ . -tOut            , data = df)
drop1(fit13quasi, test = 'F')
fit14quasi  = update(fit13quasi, .~ . -tInOp            , data = df)
drop1(fit14quasi, test = 'F')
fit15quasi  = update(fit14quasi, .~ . -time            , data = df)
drop1(fit15quasi, test = 'F')

anova(fit1quasi, fit15quasi, test ='Chisq')

fit16quasi <- update(fit15quasi, .~. + I((tInOp-mean(tInOp))^2) + I((tOut-mean(tOut))^2) + I((time-mean(time))^2), data = df)
drop1(fit16quasi, test = 'F')

fit16quasi <- update(fit16quasi, .~.  -I((tOut-mean(tOut))^2), data = df)
drop1(fit16quasi, test = 'F')
fit17quasi <- update(fit16quasi, .~.  -I((tInOp-mean(tInOp))^2), data = df)
drop1(fit17quasi, test = 'F')

```

$$clo_i = \beta_0 + \beta_1 \cdot sex_i + \epsilon_i$$

where $\epsilon \sim N(0,1)$. The residuals are assumed to be independent and identically distributed. The standard deviation of the residuals ($\hat{\sigma}$) are estimated as 1.13 and a confidence hereof are calculated based on theorem 3.5. The estimated parameters and 95\% confidence intervals calculated based on profile likelihood can be seen in table \ref{table:par_binomial}. 
To test the model reduction a likelihood-ratio-test are performed based on theorem 3.6 resulting in $p=0.84$ thereby the model reduction is kept. Basis expansions of time, indoor and outdoor temperature are tried out but these are removed due to being insignificant. 

```{r}
library(xtable)
fit15quasi$coefficients
xtable(confint(fit15quasi))


lm_sigma_conf<-function(fit,CI=0.95){
  # Book page 53: sigma_hat^2~sigma^2*chisq_f/f where f=n-k
  # rearanging: sigma_hat^2*f/chisq_f
  sigma=sigma(fit)
  d_f=fit$df.residual
  conf_sigma2=d_f*sigma^2/qchisq(c((1-CI)/2,1-(1-CI)/2), df = d_f, lower.tail = FALSE)
  conf=sqrt(conf_sigma2)
  names(conf)=paste(c((1-CI)/2,1-(1-CI)/2)*100,"%")
  return(conf)
}
sigma(fit15quasi)
lm_sigma_conf(fit15quasi)
```

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & 2.5 \% & Estimate & 97.5 \% \\ 
  \hline
$\hat{\beta_0}$ & -1.91 & -1.57 &-1.26 \\ 
  $\hat{\beta_1}$ & -1.84 & -1.18 & -0.58 \\ 
  $\hat{\sigma}$ & 1.01 & 1.13 & 1.29 \\
   \hline
\end{tabular}
\label{table:par_binomial}
\end{table}


```{r}
df$residuals = residuals(fit15quasi,type="pearson")
ggplot(data = df, aes(x = sex, y = residuals, color = sex))+ geom_boxplot() + geom_jitter()

summary(fit15quasi)
(sigsq.dev <- fit15quasi$deviance/fit15quasi$df.residual)
(sigsq.pear <- sum(residuals(fit15quasi,type="pearson")^2)/fit15quasi$df.residual)
(sigsq.devR <- sum(residuals(fit15quasi,type="deviance")^2)/fit15quasi$df.residual)
```
The overdispersions parameter is estimated as: 1.34 based on pearson residuals. 


#Generalized linear model based on Poisson distribution

A new generalized linear model similar the the one proposed above are fitted. Instead of being based on the binomial distribution the new model will be based on the Poisson distribution using the log link-function. The initial model are again the full model using all interactions, and are reduced using the backward selection method using Type III partitioning, where higher order terms are removed before lower order terms. A goodness of fit test are performed on the initial model resulting in: $p = 0.13$ and therefore passes the initial goodness of fit test. The final from the model reduction is presented below: 

```{r}
fit0  = glm(clo ~ time*factor(sex)*tOut*tInOp ,poisson(link = log), data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#Remove fourth order interaction

fit1  = update(fit0, .~ . -time:factor(sex):tOut:tInOp   , data = df)
drop1(fit1, test = 'Chisq')
1 - pchisq(fit1$deviance,df=fit1$df.residual)
#Remove sex:tOut:tInOp

fit2 = update(fit1, .~ . -factor(sex):tOut:tInOp   , data = df)
drop1(fit2, test = 'Chisq')
1 - pchisq(fit2$deviance,df=fit2$df.residual)
#Remove time:tOut:tInOp

fit3 = update(fit2, .~ . -time:tOut:tInOp   , data = df)
drop1(fit3, test = 'Chisq')
1 - pchisq(fit3$deviance,df=fit3$df.residual)
#Remove time:sex:tOut
fit4 = update(fit3, .~ . -time:factor(sex):tOut   , data = df)
drop1(fit4, test = 'Chisq')
1 - pchisq(fit4$deviance,df=fit4$df.residual)
fit5 = update(fit4, .~ . -time:factor(sex):tInOp   , data = df)
drop1(fit5, test = 'Chisq')
1 - pchisq(fit5$deviance,df=fit5$df.residual)
#Remove tOut:tInOp
fit6 = update(fit5, .~ . -tOut:tInOp   , data = df)
drop1(fit6, test = 'Chisq')
1 - pchisq(fit6$deviance,df=fit6$df.residual)
#Remove sex:tOut
fit7 = update(fit6, .~ . -factor(sex):tOut   , data = df)
drop1(fit7, test = 'Chisq')
1 - pchisq(fit7$deviance,df=fit7$df.residual)
#Remove time:tOut
fit8 = update(fit7, .~ . -time:tOut   , data = df)
drop1(fit8, test = 'Chisq')
1 - pchisq(fit8$deviance,df=fit8$df.residual)
#Remove time:tInOp
fit9 = update(fit8, .~ . -time:tInOp   , data = df)
drop1(fit9, test = 'Chisq')
1 - pchisq(fit9$deviance,df=fit9$df.residual)
#Remove sex:tInOp
fit10 = update(fit9, .~ . -factor(sex):tInOp   , data = df)
drop1(fit10, test = 'Chisq')
1 - pchisq(fit10$deviance,df=fit10$df.residual)
fit11 = update(fit10, .~ . -time:factor(sex)   , data = df)
drop1(fit11, test = 'Chisq')
1 - pchisq(fit11$deviance,df=fit11$df.residual)
#Remove tOut
fit12 = update(fit11, .~ . -tOut   , data = df)
drop1(fit12, test = 'Chisq')
1 - pchisq(fit12$deviance,df=fit12$df.residual)
#Remove tInOp
fit13 = update(fit12, .~ . -tInOp   , data = df)
drop1(fit13, test = 'Chisq')
1 - pchisq(fit13$deviance,df=fit13$df.residual)
#remove time
fit14 = update(fit13, .~ . -time   , data = df)
drop1(fit14, test = 'Chisq')
1 - pchisq(fit14$deviance,df=fit14$df.residual)
anova(fit0, fit14, test = 'Chisq')
```

$$clo_i = \beta_0 + \beta_1 \cdot sex_i + \epsilon_i$$


where $\epsilon \sim N(0,1)$. Again the reduced model passes the goodness of fit test ($p=0.16$). Also the reduced model are compared with the full initial model in order to test the model reduction (likelihood-ratio-test) and results in the following p-value: $p=0.59$ and the model reduction are therefore kept. The residuals are assumed to be independent and identically distributed. It is further tested whether including an offset will improve the performance of the model. An offset using $nobs$ are implemented. The model including the offset are also tested whether it is a sufficient model and both the full initial model and the reduced model passes the goodness of fit test (initial model: $p = 0.11$, reduced model: $0.16$). Also the reduced model containing an offset ends up with same model as presented above, but including an offset. In order to compare the model including an offset and the previous model the AIC is computed as the models are not nested. The computed AIC scores are: 270.61 and 271.03 for the model including an offset and the one without respectively. Thereby indicating that the model including the offset are best. 

```{r}
fit0offset  = glm(clo ~ time*factor(sex)*tOut*tInOp + offset(log(nobs)) ,poisson(link = log), data = df)
drop1(fit0offset, test = 'Chisq')
1 - pchisq(fit0offset$deviance,df=fit0offset$df.residual)
#Reduce with this setting --> compare 
fit1offset  = update(fit0offset, .~ . -time:factor(sex):tOut:tInOp   , data = df)
drop1(fit1offset, test = 'Chisq')
1 - pchisq(fit1offset$deviance,df=fit1offset$df.residual)

fit2offset  = update(fit1offset, .~ . -time:tOut:tInOp    , data = df)
drop1(fit2offset, test = 'Chisq')
1 - pchisq(fit2offset$deviance,df=fit2offset$df.residual)

fit3offset  = update(fit2offset, .~ . -time:factor(sex):tOut    , data = df)
drop1(fit3offset, test = 'Chisq')
1 - pchisq(fit3offset$deviance,df=fit3offset$df.residual)

fit4offset  = update(fit3offset, .~ . -time:factor(sex):tInOp    , data = df)
drop1(fit4offset, test = 'Chisq')
1 - pchisq(fit4offset$deviance,df=fit4offset$df.residual)

fit5offset  = update(fit4offset, .~ . -factor(sex):tOut:tInOp      , data = df)
drop1(fit5offset, test = 'Chisq')
1 - pchisq(fit5offset$deviance,df=fit5offset$df.residual)

fit6offset  = update(fit5offset, .~ . -tOut:tInOp      , data = df)
drop1(fit6offset, test = 'Chisq')
1 - pchisq(fit6offset$deviance,df=fit6offset$df.residual)

fit7offset  = update(fit6offset, .~ . -factor(sex):tOut       , data = df)
drop1(fit7offset, test = 'Chisq')
1 - pchisq(fit7offset$deviance,df=fit7offset$df.residual)

fit8offset  = update(fit7offset, .~ . -time:tOut       , data = df)
drop1(fit8offset, test = 'Chisq')
1 - pchisq(fit8offset$deviance,df=fit8offset$df.residual)

fit9offset  = update(fit8offset, .~ . -time:tInOp    , data = df)
drop1(fit9offset, test = 'Chisq')
1 - pchisq(fit9offset$deviance,df=fit9offset$df.residual)

fit10offset  = update(fit9offset, .~ . -time:factor(sex)    , data = df)
drop1(fit10offset, test = 'Chisq')
1 - pchisq(fit10offset$deviance,df=fit10offset$df.residual)

fit11offset  = update(fit10offset, .~ . -factor(sex):tInOp    , data = df)
drop1(fit11offset, test = 'Chisq')
1 - pchisq(fit11offset$deviance,df=fit11offset$df.residual)

fit12offset  = update(fit11offset, .~ . -tOut    , data = df)
drop1(fit12offset, test = 'Chisq')
1 - pchisq(fit12offset$deviance,df=fit12offset$df.residual)

fit13offset  = update(fit12offset, .~ . -tInOp    , data = df)
drop1(fit13offset, test = 'Chisq')
1 - pchisq(fit13offset$deviance,df=fit13offset$df.residual)

fit14offset  = update(fit13offset, .~ . -time    , data = df)
drop1(fit14offset, test = 'Chisq')
1 - pchisq(fit14offset$deviance,df=fit14offset$df.residual)

AIC(fit14offset, fit14)

```

Furthermore, basis expansions of time, indoor and outdoor temperature are tested whether this could improve the model performance. Including the basis expansion results in insignificant terms which are therefore removed. 
```{r}
fit0  = glm(clo ~ time*(sex)*tOut*tInOp + offset(log(nobs)) +
                    I((tInOp-mean(tInOp))^2) + I((tOut-mean(tOut))^2),poisson(link = log), data = df)
drop1(fit0, test = 'Chisq')
1 - pchisq(fit0$deviance,df=fit0$df.residual)
#Reduce with this setting --> compare 
fit1  = update(fit0, .~ . -I((tOut - mean(tOut))^2)   , data = df)
drop1(fit1, test = 'Chisq')
1 - pchisq(fit1$deviance,df=fit1$df.residual)

fit2  = update(fit1, .~ . -I((tInOp - mean(tInOp))^2)    , data = df)
drop1(fit2, test = 'Chisq')
1 - pchisq(fit2$deviance,df=fit2$df.residual)

fit3  = update(fit2, .~ . -time:sex:tOut:tInOp    , data = df)
drop1(fit3, test = 'Chisq')
1 - pchisq(fit3$deviance,df=fit3$df.residual)

fit4  = update(fit3, .~ . -time:sex:tOut      , data = df)
drop1(fit4, test = 'Chisq')
1 - pchisq(fit4$deviance,df=fit4$df.residual)

fit5  = update(fit4, .~ . -sex:tOut:tInOp        , data = df)
drop1(fit5, test = 'Chisq')
1 - pchisq(fit5$deviance,df=fit5$df.residual)

fit6  = update(fit5, .~ . -time:sex:tInOp       , data = df)
drop1(fit6, test = 'Chisq')
1 - pchisq(fit6$deviance,df=fit6$df.residual)

fit7  = update(fit6, .~ . -time:tOut:tInOp        , data = df)
drop1(fit7, test = 'Chisq')
1 - pchisq(fit7$deviance,df=fit7$df.residual)

fit8  = update(fit7, .~ . -tOut:tInOp       , data = df)
drop1(fit8, test = 'Chisq')
1 - pchisq(fit8offset$deviance,df=fit8offset$df.residual)

fit9  = update(fit8, .~ . -time:tOut    , data = df)
drop1(fit9, test = 'Chisq')
1 - pchisq(fit9$deviance,df=fit9$df.residual)

fit10  = update(fit9, .~ . -sex:tOut     , data = df)
drop1(fit10, test = 'Chisq')
1 - pchisq(fit10offset$deviance,df=fit10offset$df.residual)

fit11  = update(fit10, .~ . -time:sex    , data = df)
drop1(fit11, test = 'Chisq')
1 - pchisq(fit11$deviance,df=fit11$df.residual)

fit12  = update(fit11, .~ . -time:tInOp    , data = df)
drop1(fit12, test = 'Chisq')
1 - pchisq(fit12$deviance,df=fit12$df.residual)

fit13  = update(fit12, .~ . -sex:tInOp    , data = df)
drop1(fit13, test = 'Chisq')
1 - pchisq(fit12$deviance,df=fit12$df.residual)

AIC(fit12)

```

Lastly different link-functions are tested whether they can improve the model performance. 
```{r}
glm(clo ~ factor(sex) + offset(sqrt(nobs)) ,poisson(link = sqrt), data = df)
#ERROR?
#ALSO ERROR WITH TIME^2
```

The final and optimal model are the following: 

$$clo_i = \beta_0 + \beta_1 \cdot sex_i + offset(nobs_i)+ \epsilon_i$$

```{r}
lm_sigma_conf<-function(fit,CI=0.95){
  # Book page 53: sigma_hat^2~sigma^2*chisq_f/f where f=n-k
  # rearanging: sigma_hat^2*f/chisq_f
  sigma=sigma(fit)
  d_f=fit$df.residual
  conf_sigma2=d_f*sigma^2/qchisq(c((1-CI)/2,1-(1-CI)/2), df = d_f, lower.tail = FALSE)
  conf=sqrt(conf_sigma2)
  names(conf)=paste(c((1-CI)/2,1-(1-CI)/2)*100,"%")
  return(conf)
}
sigma(fit14offset)
lm_sigma_conf(fit14offset)
fit14offset$coefficients
xtable(confint(fit14offset))
anova(fit0offset, fit14offset, test = 'Chisq')
```

The standard deviation of the residuals ($\hat{\sigma}$) are estimated as 1.06 and a confidence hereof are calculated based on theorem 3.5. The estimated parameters and 95\% confidence intervals calculated based on profile likelihood can be seen in table \ref{table:par_poisson}. 
To test the model reduction a likelihood-ratio-test are performed based on theorem 3.6 resulting in $p=0.26$ thereby the model reduction is kept.

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & 2.5 \% & Estimate & 97.5 \% \\ 
  \hline
 $\hat{\beta_0}$ & -2.02 & -1.76 & -1.52 \\ 
  $\hat{\beta_1}$ & -1.60 & -1.06 & -0.56 \\
  $\hat{\sigma}$ & 0.94 & 1.06 & 1.20 \\
   \hline
\end{tabular}
\label{table:par_poisson}
\end{table}


